{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfXMWp75+FUWN1LXLxjHee"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJMS6oWayLZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa44d40-0a4d-4fed-c8d2-acc2aa8cdc45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n",
            "Cloning into 'Drowsiness-Detection'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 7 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (7/7), done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = '/content/drive/My Drive/ML_Datasets/NTHU-DDD/'"
      ],
      "metadata": {
        "id": "ecvR7fCxzvf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "-1BLQJqjPgwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the dataset for training and splitting for validation\n",
        "train_ds= tf.keras.utils.image_dataset_from_directory(\n",
        "    DATASET_PATH,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    batch_size=32,\n",
        "    image_size=(224,224), #currently using images as it is...the images will be squished as they are 640*480 initially\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "X1ztgusLUbzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(f\"Classes found: {class_names}\")"
      ],
      "metadata": {
        "id": "XL3jOzUEVicU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATASET_PATH,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "eGkYartOU1VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets see the squished images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "SrMkw-p2WxjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a pipeine for preprocessing the images\n",
        "data_augmentation= Sequential([\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.1),\n",
        "])"
      ],
      "metadata": {
        "id": "QYFWmbRCW3Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating cnn model\n",
        "model= Sequential([\n",
        "    data_augmentation,\n",
        "    layers.Rescaling(1./255, input_shape=(224,224,3)),\n",
        "    layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "qxzP1Cv7YGUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "9_qNkoTeZNIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MzqYswdXZPLA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}